{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["Vl9o3T41EDKw"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"EDq8Ijkv-NW-"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import random\n","\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.feature_selection import RFE\n","from operator import itemgetter\n","from sklearn.naive_bayes import GaussianNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn import tree"]},{"cell_type":"code","source":["from google.colab import drive\n","\n","# path from your drive to data\n","drive.mount('/content/drive/')"],"metadata":{"id":"p_d_W9hMD7aS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["After data frames of the averages of the last n games have been created, each dataframe is split into an input matrix X and a binary classification matrix y to perform Feature Selection and Machine Learning. Initially, we look at data where n = 1, 5, 10, 15, and 20 to see how feature selection methods may vary based\n","on n. We don't go above n=20 because we increase chances of model drift."],"metadata":{"id":"xu56yyKEy-9L"}},{"cell_type":"code","source":["path = '/content/drive/MyDrive/College/Senior_Year/SP/BEM_Ec_120/Project/Mens/data/n_avg_matchups/'\n","\n","# n_data_dict[n][0]: dataframe of loaded csv; each row in data frame includes winner and loser stats\n","# n_data_dict[n][1]: X_pre_2023 (input for training data)\n","# n_data_dict[n][2]: y_pre_2023 (classification for training data)\n","# n_data_dict[n][3]: X_2023 (input for testing data)\n","# n_data_dict[n][4]: y_2023 (classification for testing data)\n","\n","n = {1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,20,30}\n","n_data_dict = {}\n","\n","for key in n:\n","  n_data_dict[key] = []\n","  n_data_dict[key].append(pd.read_csv(path + 'Mavg_matchups_n={}.csv'.format(key), index_col=0))"],"metadata":{"id":"xtlWhZy5zELO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["cols = ['Season', 'Score', 'FGM', \n","        'FGA', 'FGp', 'FGM3', 'FGA3', 'FGp3', 'FTM', \n","        'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl',\n","        'Blk', 'PF', 'TSP', 'EFGp', '3PTAr', 'FTAr', \n","        'ORp', 'DRp', 'TRp', 'TR', 'Poss', 'OffRtg', 'DefRtg',\n","        'NetRtg', 'OffEff', 'DefEff', 'NetEff', \n","        'PointDiff', 'Pace','PtsPer100', 'Ar', 'TOr', \n","        'ATRatio', 'ELO', 'PythagoreanExp1', 'PythagoreanExp2']\n","\n","win_cols = ['Season', 'WScore',\n","            'WFGM', 'WFGA', 'WFGp',\n","            'WFGM3', 'WFGA3', 'WFGp3', 'WFTM',\n","            'WFTA', 'WOR', 'WDR', 'WAst',\n","            'WTO', 'WStl', 'WBlk', 'WPF',\n","            'WTSP', 'WEFGp', 'W3PTAr',\n","            'WFTAr', 'WORp', 'WDRp', 'WTR', 'WPoss',\n","            'WOffRtg', 'WDefRtg', 'WNetRtg',\n","            'WNetRtg', 'WOffEff', 'WDefEff',\n","            'WNetEff', 'WPointDiff', 'WPace',\n","            'WPtsPer100', 'WAr', 'WTOr',\n","            'WATRatio', 'WELO', 'WPythagoreanExp1', \n","            'WPythagoreanExp2']\n","\n","lose_cols = ['Season', 'LScore',\n","            'LFGM', 'LFGA', 'LFGp',\n","            'LFGM3', 'LFGA3', 'LFGp3', 'LFTM',\n","            'LFTA', 'LOR', 'LDR', 'LAst',\n","            'LTO', 'LStl', 'LBlk', 'LPF',\n","            'LTSP', 'LEFGp', 'L3PTAr',\n","            'LFTAr', 'LORp', 'LDRp', 'WTR', 'LPoss',\n","            'LOffRtg', 'LDefRtg', 'LNetRtg',\n","            'LNetRtg', 'LOffEff', 'LDefEff',\n","            'LNetEff', 'LPointDiff', 'LPace',\n","            'LPtsPer100', 'LAr', 'LTOr',\n","            'LATRatio', 'LELO', 'LPythagoreanExp1', \n","            'LPythagoreanExp2']\n","\n","# Generate input and classification matrices and add them to n_data_dict given n\n","def generate_X_y(n):\n","\n","  data = n_data_dict[n][0]\n","\n","  X = pd.DataFrame(columns=cols)\n","  X_wins = data[win_cols].copy()\n","  X_losses = data[lose_cols].copy()\n","\n","  X_wins.columns = cols\n","  X_losses.columns = cols\n","\n","  ones = [1] * len(X_wins)\n","  y_wins = list(zip(X_wins['Season'], ones))\n","  zeros = [0] * len(X_losses)\n","  y_losses = list(zip(X_wins['Season'], zeros))\n","  y_list = np.concatenate((y_wins, y_losses), axis=0)\n","\n","  X = pd.concat([X_wins.reset_index(drop=True), X_losses])\n","  y = pd.DataFrame(y_list, columns=['Season', 'WinOrLoss'])\n","\n","  X_train = X.loc[X['Season'] != 2023]\n","  X_train = X_train.drop(['Season'], axis=1)\n","  y_train = y.loc[y['Season'] != 2023]\n","  y_train = y_train.drop(['Season'], axis=1)\n","  y_train = y_train['WinOrLoss'].to_numpy()\n","\n","  n_data_dict[n].append(X_train)\n","  n_data_dict[n].append(y_train)\n","\n","  X_test = X.loc[X['Season'] == 2023]\n","  X_test = X_test.drop(['Season'], axis=1)\n","  y_test = y.loc[y['Season'] == 2023]\n","  y_test = y_test.drop(['Season'], axis=1)\n","  y_test = y_test['WinOrLoss'].to_numpy()\n","\n","  n_data_dict[n].append(X_test)\n","  n_data_dict[n].append(y_test)\n","    \n"],"metadata":{"id":"wtQMD5OwzGrc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for n in n_data_dict:\n","  generate_X_y(n)\n","  "],"metadata":{"id":"O-ZhrOqZzITk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Decide optimal value of n"],"metadata":{"id":"XMb4NzZBzMVZ"}},{"cell_type":"code","source":["num_stat_combos = 50\n","features = cols[1:]\n","stat_combos = []\n","\n","for i in range(num_stat_combos):\n","  num_features = random.randint(10, 25)\n","  combo = random.sample(features, k=num_features)\n","  stat_combos.append(combo)\n"],"metadata":{"id":"ufROV-6gzN1O"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = {1,2,3,4,5,6,7,8,9,10,11,12,13,14,15}\n","\n","accuracies_list = []\n","accuracies_index = 0\n","\n","for stat_list in stat_combos:\n","  # avg accuracies per n for specified stat combo\n","  accuracies_list_n = []\n","  for N in n:\n","\n","    data = n_data_dict[N]\n","    X_train = data[1]\n","    y_train = data[2]\n","\n","    X_train_select = X_train[stat_list]\n","\n","    # average the accuracy over runs of the model within the training data\n","    accuracies = []\n","    for _ in range(50):\n","\n","      X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train_select, y_train, test_size=0.25)\n","\n","      gnb = GaussianNB()\n","      y_pred = gnb.fit(X_train_train, y_train_train).predict(X_train_test)\n","      accuracies.append(1- ((y_train_test != y_pred).sum())/X_train_test.shape[0])\n","    \n","    # print(\"N = {}, stats = {}\".format(N, stat_list))\n","    mean = np.mean(accuracies)\n","    # print(mean)\n","    accuracies_list_n.append(mean)\n","\n","  accuracies_list.append(accuracies_list_n)"],"metadata":{"id":"VYPUfp8PzPQy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]\n","\n","plt.figure()\n","plt.xlabel(\"Average number of games taken as input (n)\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Men\\'s Random Feature Subset Accuracy per n\"\")\n","plt.xticks(np.linspace(1,15,15))\n","\n","for i in range(len(accuracies_list)):\n","  plt.plot(n, accuracies_list[i])\n","\n","plt.show()\n","\n"],"metadata":{"id":"1qaEscE4zQ0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["transposed_acc_list = np.transpose(accuracies_list)\n","\n","avg_acc = []\n","\n","for i in range(len(transposed_acc_list)):\n","  avg_acc.append(np.mean(transposed_acc_list[i]))\n","\n","print(max(avg_acc))"],"metadata":{"id":"XV8gQY49zSMM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["plt.figure()\n","plt.xlabel(\"Average number of games taken as input (n)\")\n","plt.ylabel(\"Accuracy\")\n","plt.title(\"Men\\'s Average Random Feature Subset Accuracy per n\")\n","plt.xticks(np.linspace(1,15,15))\n","\n","plt.plot(n, avg_acc)\n","plt.show()"],"metadata":{"id":"GGtZi74JzUge"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Note, model accuracy is maximized at n=6"],"metadata":{"id":"q4VEMcVdzaB1"}},{"cell_type":"markdown","source":["# Create correlation matrix of features for each n based on training data"],"metadata":{"id":"zJkuipuIzjim"}},{"cell_type":"code","source":["corr_matrix_n_list = [9]\n","for n in corr_matrix_n_list:\n","  X_pre_2023 = n_data_dict[n][1]\n","  plt.figure(figsize=(15, 12))\n","  plt.title('Men\\'s Correlation Matrix, n={}'.format(n))\n","  correlation_heatmap = sns.heatmap(X_pre_2023.corr(), annot=True, fmt =\".1f\", annot_kws={\"fontsize\":8})\n","  plt.show()"],"metadata":{"id":"x_s1-2vOzmjM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Recursive Feature Elimination"],"metadata":{"id":"mQCAtI6OzpTW"}},{"cell_type":"code","source":["regressor = RandomForestRegressor(n_estimators=100, max_depth=10)\n","num_features_to_select = 1\n","rfe = RFE(regressor, n_features_to_select=num_features_to_select, verbose=3)\n","rfe.fit(n_data_dict[9][1], n_data_dict[9][2])\n","\n","from operator import itemgetter\n","features = n_data_dict[9][1].columns.to_list()\n","for x, y in (sorted(zip(rfe.ranking_ , features), key=itemgetter(0))):\n","    print(x, y)"],"metadata":{"id":"Jjh-rITWzrUe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ranks = list(map(float, rfe.ranking_))\n","order = -1\n","minmax = MinMaxScaler()\n","ranks = minmax.fit_transform(order*np.array([ranks]).T).T[0]\n","ranks = map(lambda x: round(x, 2), ranks)\n","\n","rank_dict = dict(zip(cols[1:], ranks))\n","\n","print(rank_dict)\n","\n","rank_dict = dict(sorted(rank_dict.items(), key=lambda item: item[1], reverse=True))\n","\n","rank_df = pd.DataFrame(list(rank_dict.items()), columns=['Feature', 'RFE Ranking'])\n","\n","fig, ax = plt.subplots(figsize=(8, 8))\n","plt.title('Men\\'s RFE Ranking Plot at n=9')\n","sns.barplot(x=\"RFE Ranking\", y=\"Feature\", data=rank_df, ax=ax, palette=\"flare\")\n","plt.show()"],"metadata":{"id":"C0yW4ntizswJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"yf9JVgHrEAuC"}},{"cell_type":"markdown","source":["## SVM"],"metadata":{"id":"AnCLd09aEBye"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler \n","from sklearn.svm import SVC # \"Support vector classifier\"  \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import cross_val_score\n","\n","features_selected = ['TRp', 'Pace', 'ELO', 'PointDiff']\n","\n","X_train_selected = n_data_dict[6][1][features_selected]\n","x = X_train_selected.values\n","standard_scaler = StandardScaler()\n","x_scaled = standard_scaler.fit_transform(x)\n","X_train_selected = pd.DataFrame(x_scaled, columns=features_selected)\n","\n","y_train_selected = n_data_dict[6][2]\n","\n","X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train_selected, y_train_selected, test_size=0.3)"],"metadata":{"id":"kFnviysBzvwa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["svm = SVC(kernel='rbf', gamma='auto', C=100, random_state=0, verbose=3)  \n","y_pred = svm.fit(X_train_train, y_train_train)\n","print(\"SVM accuracy: \", svm.score(X_train_test, y_train_test))"],"metadata":{"id":"lf6CIWHt0Brq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## GNB"],"metadata":{"id":"Vl9o3T41EDKw"}},{"cell_type":"code","source":["N = 6\n","\n","stat_combos = [[\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\",\"PythagoreanExp2\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\",\"PythagoreanExp2\",\"DefRtg\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\",\"PythagoreanExp2\",\"DefRtg\",\"Score\"]]\n","\n","for stat_list in stat_combos:\n","\n","  data = pd.read_csv(\"/content/drive/MyDrive/Undergrad/Smore Year/Classes/BEM 120/mdata/n_avgs/Mavg_matchups_n={}.csv\".format(N), sep=\",\")\n","\n","  cols = ['Season', 'Score', 'FGM', \n","          'FGA', 'FGp', 'FGM3', 'FGA3', 'FGp3', 'FTM', \n","          'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl',\n","          'Blk', 'PF', 'TSP', 'EFGp', '3PTAr', 'FTAr', \n","          'ORp', 'DRp', 'TRp', 'TR', 'Poss', 'OffRtg', 'DefRtg',\n","          'NetRtg', 'OffEff', 'DefEff', 'NetEff', \n","          'PointDiff', 'Pace','PtsPer100', 'Ar', 'TOr', \n","          'ATRatio', 'ELO', 'PythagoreanExp1', 'PythagoreanExp2']\n","\n","  X = pd.DataFrame(columns=cols)\n","\n","  X_wins = data[['Season', 'WScore',\n","                        'WFGM', 'WFGA', 'WFGp',\n","                        'WFGM3', 'WFGA3', 'WFGp3', 'WFTM',\n","                        'WFTA', 'WOR', 'WDR', 'WAst',\n","                        'WTO', 'WStl', 'WBlk', 'WPF',\n","                        'WTSP', 'WEFGp', 'W3PTAr',\n","                        'WFTAr', 'WORp', 'WDRp', 'WTR', 'WPoss',\n","                        'WOffRtg', 'WDefRtg', 'WNetRtg',\n","                        'WNetRtg', 'WOffEff', 'WDefEff',\n","                        'WNetEff', 'WPointDiff', 'WPace',\n","                        'WPtsPer100', 'WAr', 'WTOr',\n","                        'WATRatio', 'WELO', 'WPythagoreanExp1', 'WPythagoreanExp2']].copy()\n","  X_wins.columns = cols\n","\n","  X_losses = data[['Season', 'LScore',\n","                        'LFGM', 'LFGA', 'LFGp',\n","                        'LFGM3', 'LFGA3', 'LFGp3', 'LFTM',\n","                        'LFTA', 'LOR', 'LDR', 'LAst',\n","                        'LTO', 'LStl', 'LBlk', 'LPF',\n","                        'LTSP', 'LEFGp', 'L3PTAr',\n","                        'LFTAr', 'LORp', 'LDRp', 'WTR', 'LPoss',\n","                        'LOffRtg', 'LDefRtg', 'LNetRtg',\n","                        'LNetRtg', 'LOffEff', 'LDefEff',\n","                        'LNetEff', 'LPointDiff', 'LPace',\n","                        'LPtsPer100', 'LAr', 'LTOr',\n","                        'LATRatio', 'LELO', 'LPythagoreanExp1', 'LPythagoreanExp2']].copy().reset_index(drop=True)\n","  X_losses.columns = cols\n","\n","  ones = [1] * len(X_wins)\n","  y_wins = list(zip(X_wins['Season'], ones))\n","\n","  zeros = [0] * len(X_losses)\n","  y_losses = list(zip(X_wins['Season'], zeros))\n","\n","  y_list = np.concatenate((y_wins, y_losses), axis=0)\n","\n","  # X -> training data\n","  # y -> classification (1 for win, 0 for loss)\n","  X = pd.concat([X_wins.reset_index(drop=True), X_losses])\n","  y = pd.DataFrame(y_list, columns=['Season', 'WinOrLoss'])\n","\n","  # data before 2023 is training split, 2023 is testing split\n","  X_train = X.loc[X['Season'] != 2023]\n","  X_train = X_train.drop(['Season'], axis=1)\n","\n","  X_test = X.loc[X['Season'] == 2023]\n","  X_test = X_test.drop(['Season'], axis=1)\n","\n","  y_train = y.loc[y['Season'] != 2023]\n","  y_train = y_train.drop(['Season'], axis=1)\n","  y_train = y_train['WinOrLoss'].to_numpy()\n","\n","  y_test = y.loc[y['Season'] == 2023]\n","  y_test = y_test.drop(['Season'], axis=1)\n","  y_test = y_test['WinOrLoss'].to_numpy()\n","\n","  X_train_select = X_train[stat_list]\n","  X_test_select = X_test[stat_list]\n","\n","  accuracies = []\n","\n","  for _ in range(50):\n","\n","    X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train_select, y_train, test_size=0.25)\n","\n","    model = GaussianNB()\n","    y_pred = model.fit(X_train_train, y_train_train).predict(X_train_test)\n","    accuracies.append(1- ((y_train_test != y_pred).sum())/X_train_test.shape[0])\n","\n","  print(stat_list)    \n","  print(np.mean(accuracies))\n","  y_test_pred = model.fit(X_train_select, y_train).predict(X_test_select)\n","  print(1- ((y_test != y_test_pred).sum())/X_test.shape[0])"],"metadata":{"id":"uhCILZxwEMaW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## DT"],"metadata":{"id":"ttacYrLTEEcT"}},{"cell_type":"code","source":["N = 6\n","\n","stat_combos = [[\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\",\"PythagoreanExp2\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\",\"PythagoreanExp2\",\"DefRtg\"],\n","               [\"TRp\",\"Pace\",\"PointDiff\",\"ELO\",\"NetRtg\",\"OffRtg\",\"PythagoreanExp2\",\"DefRtg\",\"Score\"]]\n","\n","\n","for stat_list in stat_combos:\n","\n","  data = pd.read_csv(\"/content/drive/MyDrive/Undergrad/Smore Year/Classes/BEM 120/mdata/n_avgs/Mavg_matchups_n={}.csv\".format(N), sep=\",\")\n","\n","  cols = ['Season', 'Score', 'FGM', \n","          'FGA', 'FGp', 'FGM3', 'FGA3', 'FGp3', 'FTM', \n","          'FTA', 'OR', 'DR', 'Ast', 'TO', 'Stl',\n","          'Blk', 'PF', 'TSP', 'EFGp', '3PTAr', 'FTAr', \n","          'ORp', 'DRp', 'TRp', 'TR', 'Poss', 'OffRtg', 'DefRtg',\n","          'NetRtg', 'OffEff', 'DefEff', 'NetEff', \n","          'PointDiff', 'Pace','PtsPer100', 'Ar', 'TOr', \n","          'ATRatio', 'ELO', 'PythagoreanExp1', 'PythagoreanExp2']\n","\n","  X = pd.DataFrame(columns=cols)\n","\n","  X_wins = data[['Season', 'WScore',\n","                        'WFGM', 'WFGA', 'WFGp',\n","                        'WFGM3', 'WFGA3', 'WFGp3', 'WFTM',\n","                        'WFTA', 'WOR', 'WDR', 'WAst',\n","                        'WTO', 'WStl', 'WBlk', 'WPF',\n","                        'WTSP', 'WEFGp', 'W3PTAr',\n","                        'WFTAr', 'WORp', 'WDRp', 'WTR', 'WPoss',\n","                        'WOffRtg', 'WDefRtg', 'WNetRtg',\n","                        'WNetRtg', 'WOffEff', 'WDefEff',\n","                        'WNetEff', 'WPointDiff', 'WPace',\n","                        'WPtsPer100', 'WAr', 'WTOr',\n","                        'WATRatio', 'WELO', 'WPythagoreanExp1', 'WPythagoreanExp2']].copy()\n","  X_wins.columns = cols\n","\n","  X_losses = data[['Season', 'LScore',\n","                        'LFGM', 'LFGA', 'LFGp',\n","                        'LFGM3', 'LFGA3', 'LFGp3', 'LFTM',\n","                        'LFTA', 'LOR', 'LDR', 'LAst',\n","                        'LTO', 'LStl', 'LBlk', 'LPF',\n","                        'LTSP', 'LEFGp', 'L3PTAr',\n","                        'LFTAr', 'LORp', 'LDRp', 'WTR', 'LPoss',\n","                        'LOffRtg', 'LDefRtg', 'LNetRtg',\n","                        'LNetRtg', 'LOffEff', 'LDefEff',\n","                        'LNetEff', 'LPointDiff', 'LPace',\n","                        'LPtsPer100', 'LAr', 'LTOr',\n","                        'LATRatio', 'LELO', 'LPythagoreanExp1', 'LPythagoreanExp2']].copy().reset_index(drop=True)\n","  X_losses.columns = cols\n","\n","  ones = [1] * len(X_wins)\n","  y_wins = list(zip(X_wins['Season'], ones))\n","\n","  zeros = [0] * len(X_losses)\n","  y_losses = list(zip(X_wins['Season'], zeros))\n","\n","  y_list = np.concatenate((y_wins, y_losses), axis=0)\n","\n","  # X -> training data\n","  # y -> classification (1 for win, 0 for loss)\n","  X = pd.concat([X_wins.reset_index(drop=True), X_losses])\n","  y = pd.DataFrame(y_list, columns=['Season', 'WinOrLoss'])\n","\n","  # data before 2023 is training split, 2023 is testing split\n","  X_train = X.loc[X['Season'] != 2023]\n","  X_train = X_train.drop(['Season'], axis=1)\n","\n","  X_test = X.loc[X['Season'] == 2023]\n","  X_test = X_test.drop(['Season'], axis=1)\n","\n","  y_train = y.loc[y['Season'] != 2023]\n","  y_train = y_train.drop(['Season'], axis=1)\n","  y_train = y_train['WinOrLoss'].to_numpy()\n","\n","  y_test = y.loc[y['Season'] == 2023]\n","  y_test = y_test.drop(['Season'], axis=1)\n","  y_test = y_test['WinOrLoss'].to_numpy()\n","\n","  X_train_select = X_train[stat_list]\n","  X_test_select = X_test[stat_list]\n","\n","  accuracies = []\n","\n","  for _ in range(50):\n","\n","    X_train_train, X_train_test, y_train_train, y_train_test = train_test_split(X_train_select, y_train, test_size=0.25)\n","\n","    model = tree.DecisionTreeClassifier(random_state=5)\n","    y_pred = model.fit(X_train_train, y_train_train).predict(X_train_test)\n","    accuracies.append(1- ((y_train_test != y_pred).sum())/X_train_test.shape[0])\n","\n","  print(stat_list)    \n","  print(np.mean(accuracies))\n","  y_test_pred = model.fit(X_train_select, y_train).predict(X_test_select)\n","  print(1- ((y_test != y_test_pred).sum())/X_test.shape[0])"],"metadata":{"id":"_EvBIQ4hEBZf"},"execution_count":null,"outputs":[]}]}